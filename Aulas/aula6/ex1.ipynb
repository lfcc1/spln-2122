{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# define training data\n",
    "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
    "\t\t\t['this', 'is', 'the', 'second', 'sentence'],\n",
    "\t\t\t['yet', 'another', 'sentence'],\n",
    "\t\t\t['one', 'more', 'sentence'],\n",
    "\t\t\t['and', 'the', 'final', 'sentence']]\n",
    "\n",
    "model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, sg=1)\n",
    "model.save(\"models/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "model.train([[\"hello\", \"world\"]], total_examples=1, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('system', 0.21617142856121063), ('survey', 0.044689204543828964), ('interface', 0.015203374437987804), ('time', 0.0019510634010657668), ('trees', -0.03284314647316933), ('human', -0.0742427185177803), ('response', -0.09324456751346588), ('graph', -0.09575346112251282), ('eps', -0.10513807088136673), ('user', -0.16909335553646088)]\n"
     ]
    }
   ],
   "source": [
    "vector = model.wv['computer']\n",
    "sims = model.wv.most_similar('computer', topn=10)  # get other similar words\n",
    "#print(vector)\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00515774 -0.00667028 -0.0077791   0.00831315 -0.00198292 -0.00685696\n",
      " -0.0041556   0.00514562 -0.00286997 -0.00375075  0.0016219  -0.0027771\n",
      " -0.00158482  0.0010748  -0.00297881  0.00852176  0.00391207 -0.00996176\n",
      "  0.00626142 -0.00675622  0.00076966  0.00440552 -0.00510486 -0.00211128\n",
      "  0.00809783 -0.00424503 -0.00763848  0.00926061 -0.00215612 -0.00472081\n",
      "  0.00857329  0.00428458  0.0043261   0.00928722 -0.00845554  0.00525685\n",
      "  0.00203994  0.0041895   0.00169839  0.00446543  0.00448759  0.0061063\n",
      " -0.00320303 -0.00457706 -0.00042664  0.00253447 -0.00326412  0.00605948\n",
      "  0.00415534  0.00776685  0.00257002  0.00811904 -0.00138761  0.00808028\n",
      "  0.0037181  -0.00804967 -0.00393476 -0.0024726   0.00489447 -0.00087241\n",
      " -0.00283173  0.00783599  0.00932561 -0.0016154  -0.00516075 -0.00470313\n",
      " -0.00484746 -0.00960562  0.00137242 -0.00422615  0.00252744  0.00561612\n",
      " -0.00406709 -0.00959937  0.00154715 -0.00670207  0.0024959  -0.00378173\n",
      "  0.00708048  0.00064041  0.00356198 -0.00273993 -0.00171105  0.00765502\n",
      "  0.00140809 -0.00585215 -0.00783678  0.00123304  0.00645651  0.00555797\n",
      " -0.00897966  0.00859466  0.00404815  0.00747178  0.00974917 -0.0072917\n",
      " -0.00904259  0.0058377   0.00939395  0.00350795]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Store just the words + their trained embeddings.\n",
    "word_vectors = model.wv\n",
    "word_vectors.save(\"word2vec.wordvectors\")\n",
    "\n",
    "# Load .\n",
    "wv = KeyedVectors.load(\"word2vec.wordvectors\")\n",
    "vector = wv['computer']  # Get numpy vector of a word\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "# Show all available models in gensim-data\n",
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the \"glove-twitter-25\" embeddings\n",
    "model = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Twitter', 0.8908904194831848),\n",
       " ('Twitter.com', 0.7536780834197998),\n",
       " ('tweet', 0.7431626319885254),\n",
       " ('tweeting', 0.7161932587623596),\n",
       " ('tweeted', 0.7137226462364197),\n",
       " ('facebook', 0.6988551616668701),\n",
       " ('tweets', 0.6974530816078186),\n",
       " ('Tweeted', 0.6950210928916931),\n",
       " ('Tweet', 0.6875007152557373),\n",
       " ('Tweeting', 0.6845167279243469)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mccain', 0.7319012880325317),\n",
       " ('hillary', 0.7284600138664246),\n",
       " ('obamas', 0.7229632139205933),\n",
       " ('george_bush', 0.7205674648284912),\n",
       " ('barack_obama', 0.7045838832855225),\n",
       " ('palin', 0.7043113708496094),\n",
       " ('clinton', 0.6934447884559631),\n",
       " ('clintons', 0.6816835403442383),\n",
       " ('sarah_palin', 0.6815143823623657),\n",
       " ('john_mccain', 0.6800707578659058)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('obama')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"analogia.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('queen', 0.7118193507194519)\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(x1, x2, y1):\n",
    "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
    "    return result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horrible'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('good', 'fantastic', 'bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'french'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('japan', 'france', 'japanese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'swedish'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('japan', 'german', 'japanese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'canadian'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('japan', 'canada', 'japanese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2232cce0feda495dbaab39ecfda12b4e9c75df0181da683c6fd0c1aaa6fdea1a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
